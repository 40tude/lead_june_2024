{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Part I - Train a model locally using Ray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import joblib\n",
    "from ray.util.joblib import register_ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the dataset, isolate the predictors from the target variable, and split the dataset between a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_data = pd.read_csv('https://lead-program-assets.s3.eu-west-3.amazonaws.com/M01-Distributed_machine_learning/datasets/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_card_data.loc[:, credit_card_data.columns != \"Class\"]\n",
    "y = credit_card_data.loc[:, credit_card_data.columns == \"Class\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Build a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) with two steps: a standardization, then a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "        (\"standard_scaler\", StandardScaler()),\n",
    "        (\"classifier\", RandomForestClassifier(n_estimators=100,\n",
    "                                              max_depth=5))\n",
    "    ], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the model with `joblib` using `ray` as the parallelization backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\ray\\lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "2024-06-30 15:47:12,089\tINFO ray_backend.py:74 -- Starting local ray cluster\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 15:47:17,330\tINFO worker.py:1762 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-06-30 15:47:21,704\tWARNING pool.py:589 -- The 'context' argument is not supported using ray. Please refer to the documentation for how to control ray initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  22.3s\n"
     ]
    }
   ],
   "source": [
    "register_ray()\n",
    "\n",
    "with joblib.parallel_backend('ray'):    \n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulation, you've launched a local ray cluster to parallelize a model training ! Now let's move on to parallelizing a hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define a parameter search space in the form of a dictonnary as described in the [grid search documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'classifier__n_estimators': [1,10,100],\n",
    "    'classifier__max_depth': [2,3,5,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using the ray tune wrapper for scikit-learn, launch your hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=24848)\u001b[0m c:\\Users\\phili\\anaconda3\\envs\\ray\\lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "\u001b[36m(PoolActor pid=24848)\u001b[0m   return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=24848)\u001b[0m [Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.1s\n",
      "\u001b[36m(PoolActor pid=33952)\u001b[0m [Pipeline] ........ (step 2 of 2) Processing classifier, total=   1.1s\n",
      "\u001b[36m(PoolActor pid=34328)\u001b[0m [Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.1s\u001b[32m [repeated 29x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(PoolActor pid=17620)\u001b[0m [Pipeline] ........ (step 2 of 2) Processing classifier, total=   9.9s\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=17620)\u001b[0m c:\\Users\\phili\\anaconda3\\envs\\ray\\lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(PoolActor pid=17620)\u001b[0m   return fit_method(estimator, *args, **kwargs)\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=13348)\u001b[0m [Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.1s\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(PoolActor pid=23828)\u001b[0m [Pipeline] ........ (step 2 of 2) Processing classifier, total=  18.0s\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=23828)\u001b[0m c:\\Users\\phili\\anaconda3\\envs\\ray\\lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(PoolActor pid=23828)\u001b[0m   return fit_method(estimator, *args, **kwargs)\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=32732)\u001b[0m [Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.1s\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(PoolActor pid=33952)\u001b[0m [Pipeline] ........ (step 2 of 2) Processing classifier, total= 1.2min\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(PoolActor pid=21556)\u001b[0m [Pipeline] ........ (step 2 of 2) Processing classifier, total= 2.1min\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=21556)\u001b[0m c:\\Users\\phili\\anaconda3\\envs\\ray\\lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(PoolActor pid=21556)\u001b[0m   return fit_method(estimator, *args, **kwargs)\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PoolActor pid=21556)\u001b[0m [Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing standard_scaler, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phili\\anaconda3\\envs\\ray\\lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  20.5s\n"
     ]
    }
   ],
   "source": [
    "# C'est MORT !!!\n",
    "# https://github.com/ray-project/tune-sklearn\n",
    "\n",
    "# from ray.tune.sklearn import TuneGridSearchCV\n",
    "# tune_search = TuneGridSearchCV(\n",
    "#     model, param_space\n",
    "# )\n",
    "\n",
    "# import time  # Just to compare fit times\n",
    "\n",
    "# start = time.time()\n",
    "# tune_search.fit(X_train, y_train)\n",
    "# end = time.time()\n",
    "# print(\"Tune GridSearch Fit Time:\", end - start)\n",
    "\n",
    "# print(tune_search.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import joblib\n",
    "from ray.util.joblib import register_ray\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "start = time.time()\n",
    "#search = RandomizedSearchCV(model, param_space, cv=5, n_iter=300, verbose=10)\n",
    "search = RandomizedSearchCV(model, param_space)\n",
    "\n",
    "register_ray()\n",
    "with joblib.parallel_backend('ray'):\n",
    "    search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. In production environment you would most likely have to submit your parallel jobs to a remote cluster. A remote cluster in the cloud is not cheap, so for testing purposes, let's start a ray cluster on kubernetes using our local machine on minikube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Part II - Train a model on a Ray Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the local ray cluster is still in use, let's stop it.\n",
    "```shell\n",
    "ray stop \n",
    "```\n",
    "\n",
    "As a reminder, here are the commands you may use to start your cluster on minikube: \n",
    "\n",
    "```shell\n",
    "minikube start\n",
    "```\n",
    "\n",
    "```shell\n",
    "minikube dashboard\n",
    "```\n",
    "\n",
    "```shell\n",
    "helm repo add kuberay https://ray-project.github.io/kuberay-helm/\n",
    "```\n",
    "\n",
    "```shell\n",
    "helm install kuberay-operator kuberay/kuberay-operator --version 1.0.0\n",
    "```\n",
    "\n",
    "Configure the ray cluster, you may use a .yaml file to give it more power than the default version !\n",
    "\n",
    "```shell\n",
    "helm install raycluster kuberay/ray-cluster --version 1.0.0 -f ray-cluster.yaml\n",
    "```\n",
    "\n",
    "```shell\n",
    "kubectl port-forward --address 0.0.0.0 service/raycluster-kuberay-head-svc 8265:8265\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray stop\n",
    "minikube start\n",
    "minikube dashboard\n",
    "helm repo add kuberay https://ray-project.github.io/kuberay-helm/\n",
    "helm install kuberay-operator kuberay/kuberay-operator --version 1.0.0\n",
    "helm install raycluster kuberay/ray-cluster --version 1.0.0 -f ray-cluster.yaml\n",
    "kubectl port-forward --address 0.0.0.0 service/raycluster-kuberay-head-svc 8265:8265\n",
    "\n",
    "\n",
    "# Après faut ecrire ray-train.py \n",
    "# Faire un truc du style\n",
    "ray job submit --runtime-env-json='{\\\"working_dir\\\": \\\"./\\\", \\\"pip\\\": [\\\"requests==2.26.0\\\", \\\"numpy\\\", \\\"joblib\\\", \\\"scikit-learn\\\"]}' --address=\"http://127.0.0.1:8265\" -- python ray_train.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Now that our cluster is up and running, write a script to submit a hyperparameter tuning job to our cluster, and submit using the ray CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Part III - Send the model logs to MLFLOW\n",
    "\n",
    "For this part, you need to include mlflow in your script development so that information regarding your model be logged in an mlflow tracking server.\n",
    "\n",
    "The solution is in the resources section of JULIE under part3_fight_against_financial_crime_mlflow_solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
